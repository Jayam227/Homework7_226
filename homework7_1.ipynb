{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4znqCfAiGMd"
      },
      "outputs": [],
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.dummy_operator import DummyOperator\n",
        "from airflow.providers.snowflake.operators.snowflake import SnowflakeOperator\n",
        "from datetime import datetime\n",
        "\n",
        "# Default arguments for the DAG\n",
        "default_args = {\n",
        "    'owner': 'Jayam',\n",
        "    'start_date': datetime(2023, 1, 1),\n",
        "    'email_on_failure': False\n",
        "}\n",
        "\n",
        "# Define the DAG\n",
        "with DAG('simplified_snowflake_etl_dag',\n",
        "         default_args=default_args,\n",
        "         schedule_interval='@daily',\n",
        "         catchup=False) as dag:\n",
        "\n",
        "    # Task 1: Set Stage - Create tables and set the stage\n",
        "    my_stage = SnowflakeOperator(\n",
        "        task_id='my_stage',\n",
        "        sql=\"\"\"\n",
        "            -- Create user_session_channel and session_timestamp tables if not exists\n",
        "            CREATE TABLE IF NOT EXISTS dev.raw_data.user_session_channel (\n",
        "                userId int not NULL,\n",
        "                sessionId varchar(32) primary key,\n",
        "                channel varchar(32) default 'direct'\n",
        "            );\n",
        "\n",
        "            CREATE TABLE IF NOT EXISTS dev.raw_data.session_timestamp (\n",
        "                sessionId varchar(32) primary key,\n",
        "                ts timestamp\n",
        "            );\n",
        "\n",
        "            -- Create or replace the S3 stage\n",
        "            CREATE OR REPLACE STAGE dev.raw_data.blob_stage\n",
        "            url = 's3://s3-geospatial/readonly/'\n",
        "            file_format = (type = csv, skip_header = 1, field_optionally_enclosed_by = '\"');\n",
        "        \"\"\",\n",
        "        snowflake_conn_id='admin_snowflake_conn'\n",
        "    )\n",
        "\n",
        "    # Task 2: Load Data - Copy data from S3 into Snowflake tables\n",
        "    load_mydata = SnowflakeOperator(\n",
        "        task_id='load_mydata',\n",
        "        sql=\"\"\"\n",
        "            -- Load data into user_session_channel table\n",
        "            COPY INTO dev.raw_data.user_session_channel\n",
        "            FROM @dev.raw_data.blob_stage/user_session_channel.csv;\n",
        "\n",
        "            -- Load data into session_timestamp table\n",
        "            COPY INTO dev.raw_data.session_timestamp\n",
        "            FROM @dev.raw_data.blob_stage/session_timestamp.csv;\n",
        "        \"\"\",\n",
        "        snowflake_conn_id='admin_snowflake_conn'\n",
        "    )\n",
        "    # Task dependencies\n",
        "    my_stage >> load_mydata"
      ]
    }
  ]
}